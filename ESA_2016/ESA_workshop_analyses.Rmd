---
title: "ESA Workshop"
date: "8 August, 2016"
output:
  pdf_document:
    citation_package: natbib
bibliography: bibliography.bib
---

In this portion of the workshop, we will demonstrate the approaches we will use to analyze the LTER metacommunity datasets. Today, we will walk through the following analyses:  

1) Diversity Partitioning [@Jost2007]

2) Variation Partitioning [@Borcard1992; @Legendre2005]

3) Elements of Metacommunity Structure [@Leibold2002; @Presley2010]

## Initial Setup
First, we will setup RStudio so it knows where to find our data files. We also load the R packages required to conduct the analyses. The loop below will try to load the packages and install them if needed.

```{r, message=FALSE}
# Set working environment
rm(list = ls())
setwd("~/GitHub/ltermetacommunities/ESA_2016/")

# Check for and install required packages
for (package in c('dplyr', 'tidyr', 'vegetarian', 'vegan', 'metacom')) {
  if (!require(package, character.only=T, quietly=T)) {
    install.packages(package)
    library(package, character.only=T)
  }
}
```

## Dataset: NWT Plant Communities


```{r}
# Read in NWT plant community data and site coordinates 
nwt.xy <- read.csv("NWT_coordinates.csv")
nwt.comm.long <- read.csv("NWT_plantcomp.csv")[,c(2,4,5,6)]
dim(nwt.comm.long) # note long format

# Convert to wide format
nwt.comm.wide <- tidyr::spread(nwt.comm.long, 
                               USDA_code, abund,
                               fill = 0)
dim(nwt.comm.wide) # note wide format
```


## Metacommunity analyses at a single time point:

Here, we will demonstrate the analyses at one time point. Here, we'll look at the NWT community during the year 2006. 

```{r}
# First, we'll select an individual year
nwt.2006 <- filter(nwt.comm.wide, year == 2006)
head(nwt.2006)
nwt.2006 <- nwt.2006[,-c(1:2)] # remove the plot and year columns
nwt.2006 <- nwt.2006[,-which(colSums(nwt.2006) == 0)] # remove empty columns
dim(nwt.2006)
```

### Diversity Paritioning
Using the vegatarian package, we can partition metacommunity diversity into its local (alpha), among-site (beta) and regional (gamma) components. Additionally, we can use metrics that are biased toward rare taxa (e.g., richness, where rare and common taxa are weighted equally) or common taxa (e.g., Simpson's index). 

```{r}
# q = 0, Richness (biased toward rare species)
(nwt.2006.0.a <- vegetarian::d(nwt.2006, lev = "alpha", q = 0))
(nwt.2006.0.b <- vegetarian::d(nwt.2006, lev = "beta", q = 0))
(nwt.2006.0.g <- vegetarian::d(nwt.2006, lev = "gamma", q = 0))

# q = 1, Shannon 
(nwt.2006.1.a <- vegetarian::d(nwt.2006, lev = "alpha", q = 1))
(nwt.2006.1.b <- vegetarian::d(nwt.2006, lev = "beta", q = 1))
(nwt.2006.1.g <- vegetarian::d(nwt.2006, lev = "gamma", q = 1))

# q = 2, Simpson (biased toward common species)
(nwt.2006.2.a <- vegetarian::d(nwt.2006, lev = "alpha", q = 2))
(nwt.2006.2.b <- vegetarian::d(nwt.2006, lev = "beta", q = 2))
(nwt.2006.2.g <- vegetarian::d(nwt.2006, lev = "gamma", q = 2))
```

### Variation Partitioning
We can also partition community variation into proportions explained by variation in spatial (e.g., x and y coordinates) and environmental (e.g., elevation) variables. 

To represent spatial variation we'll use the spatial eigenfunction framework, Moran's eigenvector maps (MEMs) [@Dray2006]. In particular, we'll use a special case known as Principal Coordinates of Neighbor Matrices (PCNM), which maps spatial structures from broad to fine scales using a combination of different sine waves [@Borcard2002, @Borcard2004].

```{r}
# Construct the spatial matrix
nwt.xy.dist <- dist(nwt.xy[,2:3])
nwt.pcnm <- vegan::pcnm(nwt.xy.dist, dist.ret = T)
nwt.pcnm <- scores(nwt.pcnm)[,which(nwt.pcnm$values > 0)]
nwt.pcnm <- as.data.frame(nwt.pcnm)

# Construct the "environmental" matrix
nwt.env <- as.data.frame(nwt.xy[,4]) # elevation
colnames(nwt.env) <- "elevation"

# We can Hellinger-transform the community data for use with RDA
nwt.2006.hel <- decostand(nwt.2006, method = "hellinger")
```

Now, we can perform variation partitioning. Let's use the Hellinger-transformed data first and perform a traditional redundancy analysis (RDA). RDA preserves Euclidean distances, and the Hellinger transformation maintains ecological relevance [@Legendre2001]. 

```{r}
(nwt.2006.varpart <- vegan::varpart(nwt.2006.hel, nwt.env, nwt.pcnm))
```

### Elements of Metacommunity Structure
Now, we will use incidence matrices for the EMS framework. The EMS framework uses co-occurrence patterns to characterize metacommunity structure by identifying coherence (i.e., how discontinuous are species distributions), turnover (i.e., how different is community composition across sites), and boundary clumping (i.e., is turnover gradual or punctuated?). The patterns are then characterized as checkerboard, Clementsian, Gleasonian, nested distributions, and evenly spaced (random) [@Leibold2002, @Presley2010].
```{r}
ems.2006 <- Metacommunity(
  decostand(nwt.2006[-which(rowSums(nwt.2006) == 0),], method = "pa"),
  method = "r1", sims = 100)
str(ems.2006)
IdentifyStructure(ems.2006)
```


## Metacommunity analyses across a time series

Now, we can repeat these analyses across the long-term datasets and identify shifts in the local versus among-site diversity, the relative importance of metacommunity processes, and species distribution patterns.

```{r}
# This function accepts wide-format dataset and prints analysis output
fn.mc.loop <- function(comm.wide = comm.wide, output = output){
  
  
  for(year.i in unique(comm.wide$year)){
    comm.year <- filter(comm.wide, year == year.i)[,-c(1:2)] # remove plot & year cols
    
    # Diversity Partitioning
    comm.year.0.a <- vegetarian::d(comm.year, lev = "alpha", q = 0)
    comm.year.0.b <- vegetarian::d(comm.year, lev = "beta", q = 0)
    comm.year.0.g <- vegetarian::d(comm.year, lev = "gamma", q = 0)
    
    comm.year.1.a <- vegetarian::d(comm.year, lev = "alpha", q = 1)
    comm.year.1.b <- vegetarian::d(comm.year, lev = "beta", q = 1)
    comm.year.1.g <- vegetarian::d(comm.year, lev = "gamma", q = 1)
    
    comm.year.2.a <- vegetarian::d(comm.year, lev = "alpha", q = 2)
    comm.year.2.b <- vegetarian::d(comm.year, lev = "beta", q = 2)
    comm.year.2.g <- vegetarian::d(comm.year, lev = "gamma", q = 2)
    
    # Variation Partitioning
    comm.year.hel <- decostand(comm.year, method = "hellinger")
    comm.year.varpart <- vegan::varpart(comm.year.hel, nwt.env, nwt.pcnm)
    vp <- vector(length = 4)
    vp <- comm.year.varpart$part$indfract$Adj.R.squared
    vp.a <- vp[1]
    vp.b <- vp[2]
    vp.c <- vp[3]
    vp.d <- vp[4]
    
    # EMS
    comm.year.pa <- decostand(comm.year, method = "pa")
    comm.year.pa <- comm.year.pa[,which(colSums(comm.year.pa) > 0)] # remove empty cols and rows
    comm.year.pa <- comm.year.pa[which(rowSums(comm.year.pa) > 0),]
    ems.year <- Metacommunity(
      comm.year.pa,
      method = "r1", sims = 100)
    comm.year.ems.struc <- (IdentifyStructure(ems.year))  # prints the structure of the MC
    
    # Write Output
    site.output <- c(year.i,
                     comm.year.0.a, comm.year.0.b, comm.year.0.g,
                     comm.year.1.a, comm.year.1.b, comm.year.1.g, 
                     comm.year.2.a, comm.year.2.b, comm.year.2.g,
                     vp.a, vp.b, vp.c, vp.d, comm.year.ems.struc)
    # print(site.output)
    output[which(rownames(output) == year.i), ] <- site.output
  }
  return(output)
}
```

Now, call the function:
```{r, warning = F}
# Create summary data frame
nwt.time.series <- data.frame(year = unique(nwt.comm.wide$year),
                             d.0.a = NA, d.0.b = NA, d.0.g = NA,
                             d.1.a = NA, d.1.b = NA, d.1.g = NA,
                             d.2.a = NA, d.2.b = NA, d.2.g = NA,
                             vp.a = NA, vp.b = NA, vp.c = NA, vp.d = NA,
                             ems.struc = NA)
rownames(nwt.time.series) <- nwt.time.series$year

mc.time.series.summary <- fn.mc.loop(comm.wide = nwt.comm.wide, output = nwt.time.series)
print(mc.time.series.summary)
```
